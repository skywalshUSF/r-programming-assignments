[
  {
    "path": "posts/2025-09-22-module-5-assignment/",
    "title": "Module 5 Assignment",
    "description": "Doing Math in R",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-22",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-05-Doing-Math-in-R-Part-1\r\n\r\n\r\n#Module #4 post for my LIS4370 blog. Welcome!\r\n\r\n# Task 1- Create the matrices\r\n\r\n# In R, define\r\nA <- matrix(1:100, nrow = 10)\r\nB <- matrix(1:1000, nrow = 10)\r\n\r\n# Task 2 - Inspect dimensions\r\n\r\n# Verify whether each matrix is square\r\ndim(A) # should be 10 x 10\r\n\r\n[1] 10 10\r\n\r\ndim(B) # 10 x 100 - not square\r\n\r\n[1]  10 100\r\n\r\n# Task 3 - Compute inverse and determinant\r\n\r\n# Use solve() and det(); handle errors for non-square or singular matrices:\r\n\r\n# For A\r\ninvA <- tryCatch(solve(A), error = function(e) print(e))\r\n\r\n<simpleError in solve.default(A): Lapack routine dgesv: system is exactly singular: U[6,6] = 0>\r\n\r\ndetA <- det(A)\r\n\r\n# For B, use tryCatch to capture errors\r\ninvB <- tryCatch(solve(B), error = function(e) print(e))\r\n\r\n<simpleError in solve.default(B): 'a' (10 x 100) must be square>\r\n\r\ndetB <- tryCatch(det(B), error = function(e) print(e))\r\n\r\n<simpleError in determinant.matrix(x, logarithm = TRUE, ...): 'x' must be a square matrix>\r\n\r\n# Task 4 - Document your results\r\n\r\n# R code is shown above for creating A and B, and for computing invA, detA,\r\n# invB, and detB\r\n\r\n# Output or error messages for each operation.\r\n\r\n# A brief explanation:\r\n\r\n# Why solve(A) and det(A) work.\r\n\r\n# In my operation test, solve(A) did not work. Instead, I got an error message\r\n# stating that the object 'invA' was not found. When I created the first matrix\r\n# A, and applied the solve() function, the output turned out to be a message\r\n# stating that system is exactly singular: U[6,6] = 0. This is because not all\r\n# square matrices have an inverse matrix. If the determinant of the matrix is\r\n# zero, which was the output for the determinant of matrix A (detA), then it\r\n# will not have an inverse, and the matrix is said to be singular.\r\n\r\n# Even though det(A) successfully printed out a value, the output of zero\r\n# indicates that this matrix is not non-singular and there is no inverse\r\n# solution in matrix A.\r\n\r\n# Why operations on B fail (non‑square matrix).\r\n\r\n# The operations fail to work on matrix B because it does not contain an equal\r\n# amount of rows and columns on its dimensions. The dimensions of matrix B are\r\n# 10:100, which is a non-square matrix that does not have any inverse solutions\r\n# or estimated regression parameters. This means that neither variables ('invB'\r\n# and 'detB') nor solve(B) and det(B) will generate a result.\r\n\r\n# Any notes on numeric stability or performance.\r\n\r\n# The notes that I have on numeric stability include what determinants are and\r\n# how they can be used to find the inverse of a matrix. This helps to understand\r\n# how to compute the most accurate results according to the appropriate use of\r\n# matrix math, along with having proper runtime and syntax in computer programs\r\n# without any errors to perform the requested operations correctly. This should\r\n# be important to remember whenever we create a visual that describes a\r\n# relationship between quantities that change at a constant rate, like a\r\n# straight line plotted on a graph.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2025-09-22T14:36:28-04:00",
    "input_file": "module-5-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-15-module-4-assignment/",
    "title": "Module 4 Assignment",
    "description": "Programming Structure in R",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-15",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-04-Programming-Structure\r\n\r\n\r\n#Module #4 post for my LIS4370 blog. Welcome!\r\n\r\n#Task 1 - Data Preparation and Cleaning\r\n\r\n#Define each vector in R, converting categorical strings to numeric codes\r\n#(bad=1,good=0) (low=0,high=1) and handling NA's appropriately:\r\n\r\nFrequency<-c(0.6,0.3,0.4,0.4,0.2,0.6,0.3,0.4,0.9,0.2)\r\nBloodPressure<-c(103,87,32,42,59,109,78,205,135,176)\r\nFirstAssess<-c(1,1,1,1,0,0,0,0,NA,1) ##(bad=1,good=0)\r\nSecondAssess<-c(0,0,1,1,0,0,1,1,1,1) ##(low=0,high=1)\r\nFinalDecision<-c(0,1,0,1,0,1,0,1,1,1) ##(low=0,high=1)\r\n\r\ndf_hosp<-data.frame(Frequency,BloodPressure,FirstAssess,SecondAssess,FinalDecision,stringsAsFactors = FALSE)\r\n\r\n#Inspect and handle NA's\r\nsummary(df_hosp)\r\n\r\n   Frequency    BloodPressure     FirstAssess      SecondAssess\r\n Min.   :0.20   Min.   : 32.00   Min.   :0.0000   Min.   :0.0  \r\n 1st Qu.:0.30   1st Qu.: 63.75   1st Qu.:0.0000   1st Qu.:0.0  \r\n Median :0.40   Median : 95.00   Median :1.0000   Median :1.0  \r\n Mean   :0.43   Mean   :102.60   Mean   :0.5556   Mean   :0.6  \r\n 3rd Qu.:0.55   3rd Qu.:128.50   3rd Qu.:1.0000   3rd Qu.:1.0  \r\n Max.   :0.90   Max.   :205.00   Max.   :1.0000   Max.   :1.0  \r\n                                 NA's   :1                     \r\n FinalDecision\r\n Min.   :0.0  \r\n 1st Qu.:0.0  \r\n Median :1.0  \r\n Mean   :0.6  \r\n 3rd Qu.:1.0  \r\n Max.   :1.0  \r\n              \r\n\r\ndf_hosp<-na.omit(df_hosp)\r\n\r\n#Task 2 - Generate Basic Visualizations\r\n\r\n# A. Side-by-Side Boxplots\r\nboxplot(BloodPressure~FirstAssess,data = df_hosp,names = c(\"Good\",\"Bad\"),ylab = \"Blood Pressure\",main = \"BP by First MD Assessment\")\r\n\r\n\r\nboxplot(BloodPressure~SecondAssess,data = df_hosp,names = c(\"Low\",\"High\"),ylab = \"Blood Pressure\",main = \"BP by Second MD Assessment\")\r\n\r\n\r\nboxplot(BloodPressure~FinalDecision,data = df_hosp,names = c(\"Low\",\"High\"),ylab = \"Blood Pressure\",main = \"BP by Final Decision\")\r\n\r\n\r\n# B. Histograms\r\n# Visualize overall distributions of Frequency and Blood Pressure\r\nhist(df_hosp$Frequency,breaks = seq(0,1,by=0.1),xlab = \"Visit Frequency\",main = \"Histogram of Visit Frequency\")\r\n\r\n\r\nhist(df_hosp$BloodPressure,breaks = 8,xlab = \"Blood Pressure\",main = \"Histogram of Blood Pressure\")\r\n\r\n\r\n#Task 3 - Interpretation and Discussion\r\n# 2-3 paragraphs addressing:\r\n# How blood pressure varies with each Doctor's assessment and the final decision:\r\n\r\n# For the first boxplot chart, the BP by first MD Assessment, the maximum looks\r\n# to be around 200 for good and 175 for bad. This is strange because a patient\r\n# with good blood pressure should not have readings higher than 150. The minimums\r\n# are around 60 for good and 30 for bad. This is also strange because I do not\r\n# know if it is possible for humans to have a blood pressure of 30. The median\r\n# seems about the same at 90-95. I also think the data may be misrepresented here\r\n# because both extreme high and low blood pressure should be in the bad category\r\n# and not the good category.\r\n\r\n# For the second boxplot chart, the BP by second MD Assessment, this chart shows\r\n# a better representation of the low blood pressure with a more reasonable range\r\n# between 60-110. However, the high blood pressure range seems to be problematic\r\n# because it also includes values that are in the low blood pressure range. Overall,\r\n# the high blood pressure range seems too large, ranging from around 20-200.\r\n\r\n# For the third boxplot, the BP by Final Decision, this seems to be the chart\r\n# that best represents the data. The low blood pressure seems reasonable with the\r\n# exception of some outliers. The grey area for the low blood pressure seems to\r\n# best represent the range of low blood pressure from 50-100, and the grey area\r\n# for the high blood pressure best represents the range of high blood pressure\r\n# from 90-175.\r\n\r\n# Any notable patterns or outliers in the histograms:\r\n\r\n# After reviewing the output from the histograms, a notable pattern that I found\r\n# in the data was in the histogram of blood pressure that shows the pattern\r\n# between the domain of blood pressure and the range of frequency. The pattern I\r\n# noticed is that patients who had a low blood pressure of 50 and a high blood\r\n# pressure of 110 had a higher frequency. The extreme outliers with a high blood\r\n# pressure of 175 and over 200 were displayed as well.\r\n\r\n# Potential clinical implications or limitations of this made up data:\r\n\r\n# A potential clinical implication/limitation of this made up data is that the\r\n# extreme blood pressure measurements in the histogram of blood pressure may not\r\n# be entirely accurate. Extreme high blood pressures can be caused by certain\r\n# reactions or behaviors, however, the blood pressure outliers may seem too high\r\n# for a patient who has good blood pressure.\r\n\r\n# How handling of NA values affected your analysis:\r\n\r\n# Handling NA values affected my analysis. NA values would reduce or alter the\r\n# analysis because it would exclude patient data. If an NA is removed, it would\r\n# turn into zero. It is strange to remove NA's this way because zero can mean\r\n# both high or low. Having a value of zero for a patient would cause a patient\r\n# to be placed in a good blood pressure when really they do not, or be placed\r\n# in a bad blood pressure when really they have a good reading. This is probably\r\n# what caused the data to become made up.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2025-09-15-module-4-assignment/module-4-assignment_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2025-09-15T19:26:11-04:00",
    "input_file": "module-4-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-05-module-3-assignment/",
    "title": "Module 3 Assignment",
    "description": "Introduction to Data Frame",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-05",
    "categories": [],
    "contents": "\r\nTask 1. Define and Inspect Your Data\r\nIn R, create vectors (correcting any syntax issues):\r\n\r\n\r\nName <- c(\"Jeb\",\"Donald\",\"Ted\",\"Marco\",\"Carly\",\"Hillary\",\"Bernie\")\r\nABC_poll <- c(4,62,51,21,2,14,15)\r\nCBS_poll <- c(12,75,43,19,1,21,19)\r\n\r\n# Combine into a data frame\r\ndf_polls <- data.frame(Name, ABC_poll, CBS_poll)\r\n\r\n# Use str() and head() to inspect your data frame.\r\nstr(df_polls)\r\n\r\n'data.frame':   7 obs. of  3 variables:\r\n $ Name    : chr  \"Jeb\" \"Donald\" \"Ted\" \"Marco\" ...\r\n $ ABC_poll: num  4 62 51 21 2 14 15\r\n $ CBS_poll: num  12 75 43 19 1 21 19\r\n\r\nhead(df_polls)\r\n\r\n     Name ABC_poll CBS_poll\r\n1     Jeb        4       12\r\n2  Donald       62       75\r\n3     Ted       51       43\r\n4   Marco       21       19\r\n5   Carly        2        1\r\n6 Hillary       14       21\r\n\r\nTask 2. Compute Summary Statistics\r\n\r\n\r\n# Compute the mean, median, and range for each poll:\r\n\r\n# Here is the mean, median, and range for the ABC polls\r\nmean(df_polls$ABC_poll)\r\n\r\n[1] 24.14286\r\n\r\nmedian(df_polls$ABC_poll)\r\n\r\n[1] 15\r\n\r\nrange(df_polls$ABC_poll)\r\n\r\n[1]  2 62\r\n\r\n# Here is the mean, median, and range for the CBS polls\r\nmean(df_polls$CBS_poll)\r\n\r\n[1] 27.14286\r\n\r\nmedian(df_polls$CBS_poll)\r\n\r\n[1] 19\r\n\r\nrange(df_polls$CBS_poll)\r\n\r\n[1]  1 75\r\n\r\n# Add a column for the difference between CBS and ABC:\r\ndf_polls$Diff<-df_polls$CBS_poll-df_polls$ABC_poll\r\n\r\n# Here is a bar chart that shows the difference or discrepancies\r\nlibrary(ggplot2)\r\n\r\nggplot(df_polls,aes(x=Name,y=Diff,color=Diff,fill=Diff))+\r\n  geom_bar(stat=\"identity\")+\r\n  ggtitle(\"Difference between CBS poll and ABC poll\")\r\n\r\n\r\n\r\nTask 3. Discuss and Reflect\r\nOn your blog, write 2-3 paragraphs addressing:\r\nKey patterns you observe (e.g., which candidate shows the largest discrepancies).\r\nI was able to observe multiple key patterns. Both ABC and CBS polls show that Donald had the highest values in the polls, whereas Carly had the lowest values in the polls. The mean of ABC polls, 24.14286, and the mean of the CBS polls, 27.14286, indicates that both mean values are close to each other and are somewhat similar. The median of ABC polls, 15, and the median of the CBS polls, 19, indicates that both median values are close to each other and are somewhat similar, but a difference of 4 could be significant. The range of ABC polls, from 2-62, and the range of the CBS polls, from 1-75, are somewhat similar. Donald had the largest discrepancies with a difference of 13 between the ABC_poll and the CBS_poll.\r\nImpact of using made‑up data—what limitations does this introduce\r\nThe impact of using made-up data is significant. When making up numbers, the data can influence believers that it can be true. There could be a Fox News poll online that shows Donald getting the highest value. There are some limitations to this though. The data constantly changes in a poll before the final result, and the numbers may not accurately represent the polls if the data was not retrieved at a later time after it has been fully gathered.\r\nHow you might collect or validate real poll data in a true analysis.\r\nI might collect or validate real poll data in a true analysis by showing data from side-by-side instead of only showing differences. Showing data from side-by-side gives a better graphical representation of the actual numbers that are viewed and provides an easier comparison. It also helps to have a large sample size and to verify that the data from any particular source is accurate.\r\nInclude your R code (in a code chunk) and the generated plot.\r\n\r\n\r\nlibrary(tidyverse)\r\nlongData<-df_polls|>\r\n  select(Name,\r\n         ABC_poll,\r\n         CBS_poll) |>\r\npivot_longer(cols=c(\"ABC_poll\",\"CBS_poll\"),names_to = \"Poll\")\r\n\r\ndf_polls$Name<-as.factor(df_polls$Name)\r\n\r\nggplot(longData, aes(x=Name,y=value,colour=Poll,fill=Poll))+\r\n  geom_bar(stat = \"identity\",position = \"dodge\")+\r\n  geom_text(aes(label=value),vjust=-0.5,hjust=0.5)+\r\n  ggtitle(\"ABC vs. CBS Poll Data by Candidate\")\r\n\r\n\r\n\r\nHere is a link to my blog and a screenshot of my updated github repo\r\nhttps://lis4370-r-programming-journal.netlify.app/\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-09-05-module-3-assignment/poll.jpg?raw=true",
    "last_modified": "2025-09-15T15:40:07-04:00",
    "input_file": "module-3-assignment.knit.md"
  },
  {
    "path": "posts/2025-08-30-module-2-assignment/",
    "title": "Module 2 Assignment",
    "description": "Introduction to Basic R Functions and Data Structures",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-08-30",
    "categories": [],
    "contents": "\r\nTask 1. Download Import Instructions\r\nI have successfully downloaded the document and read the instructions in the cheat sheet carefully. The methods in the “readr” and “tidyr” packages to read and write data files, save data, handle missing values, expand tables, and split cells all seem very familiar to me.\r\nTask 2. Read Assigned Chapters\r\nI have successfully read the assigned chapters on R Programming and GitHub\r\nTask 3. Evaluate myMean function\r\n\r\n\r\n# Use the vector:\r\n\r\nassignment2 <- c(16, 18, 14, 22, 27, 17, 19, 17, 17, 22, 20, 22)\r\n\r\n# Consider this function:\r\nmyMean <- function(assignment2) {\r\n  return(sum(assignment) / length(someData))\r\n}\r\n\r\n# In RStudio, run myMean(assignment2) and record the output or error.\r\nmyMean(assignment2)\r\n\r\nError in myMean(assignment2): object 'assignment' not found\r\n\r\n# The error message is displayed above.\r\n\r\n\r\nThe function fails because the variable “assignment” does not exist since it has not been created yet. Also, the variable “someData” does not exist. In order to use these two variables, they have to be declared before they are used as arguments for functions. The only variable that can be used in the “myMean” function would be “assignment2” because it is the input variable for the function.\r\nHere is a corrected version of “myMean” that correctly returns the mean of “assignment2”\r\n\r\n\r\n# The corrected function\r\nmyMean <- function(assignment2) {\r\n  return(sum(assignment2) / length(assignment2))\r\n}\r\n\r\n# Call the corrected function\r\nmyMean(assignment2)\r\n\r\n[1] 19.25\r\n\r\nHere is a screenshot that displays my GitHub repository updated with the blog link and corrected myMean function:\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-08-30-module-2-assignment/error2.jpg?raw=true",
    "last_modified": "2025-08-30T16:06:46-04:00",
    "input_file": "module-2-assignment.knit.md"
  },
  {
    "path": "posts/2025-08-25-module-1-assignment-1/",
    "title": "Module 1 Assignment 1",
    "description": "First Post.",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-08-25",
    "categories": [],
    "contents": "\r\nThis is my first post for LIS4370\r\nTask #1\r\nCreate a GitHub Repository with a README.md file:\r\n\r\nTask #2 Set Up a Blog\r\nhttps://lis4370-r-programming-journal.netlify.app/\r\nTask #3 Install R and RStudio\r\n\r\nThe installation process of RStudio required me to install R first because\r\nRStudio relies on the R programming language for its functionality. The process\r\nbegan with going to the R project website to download the file for my operating\r\nsystem, and then run the installer. Once it was installed, I was able to go to\r\nthe website that allowed me to download the desktop installer for RStudio.\r\nThe main issue I encountered during installation was that it was difficult to\r\nhave the right Windows installer to be able to download it successfully. This\r\nproblem is what caused me to install RStudio repetitively. The way I resolved\r\nthis problem is that I got the right runtime application that supports the\r\ninstallation requirements for RStudio.\r\nIn terms of my system details, I ran a Windows 11 operating system on my PC, the\r\nR version that I currently have is R 4.4.2, and RStudio version is 2024.12.0.467.\r\nTask #4 Read Foundational Chapters\r\nAn R vector is an object or entity that acts as a container to store data. The\r\nvector is the simplest way to store more than one data value in R programs.\r\nVectors are important for data analysis because they can hold different data\r\ntypes or modes in one container. After storing data types in the container, R\r\nprograms and applications can iterate over the elements in the vector and\r\nperform many different types of operations on the different modes or types of\r\ndata contained in the vector for further analysis and extracting meaning out of\r\nlarge data sets. Elements in vectors can be modified and updated, which makes\r\nthem flexible and versatile, so if data changes, a vector is a good way to keep\r\ntrack of variables.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/R-Programming-Journal-Skylar-Walsh/blob/main/_posts/2025-08-25-module-1-assignment-1/githubrepo.png?raw=true",
    "last_modified": "2025-08-29T13:51:25-04:00",
    "input_file": "module-1-assignment-1.knit.md"
  }
]
