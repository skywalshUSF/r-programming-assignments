[
  {
    "path": "posts/2025-11-10-module-12-assignment/",
    "title": "Module 12 Assignment",
    "description": "Basics of R Markdown Authoring and Document Structure",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-11-10",
    "categories": [],
    "contents": "\r\nThis is my Module 12 blog post for LIS4370.\r\nTask: 1 - Create an R Markdown File\r\nIn RStudio, go to File, New File, R Markdown… and choose HTML output.\r\nGive it a title (e.g., “My R Markdown Primer”) and author metadata.\r\nI completed this task successfully\r\nTask: 2 - Populate the Document\r\nWrite sections that include:\r\nA brief introduction explaining what R Markdown is.\r\n\r\n\r\n# R Markdown is a document type that has the capability to combine r code and\r\n# many other types of text into one document or file in various formats.\r\n\r\n# If I were to create a markdown file in RStudio, it would have a .rmd file and\r\n# some metadata at the top as the head that talks about or gives information\r\n# about the document. I can add text, images, and even links to other webpages\r\n# using HTML, and then add executable chunks of R code that will be run when\r\n# the markdown file is knitted or compiled.\r\n\r\n\r\nAt least one narrative paragraph (Markdown text).\r\nFor the following example, I will load the corrplot R package which does not\r\ncontain any built-in example datasets of its own. So to use the package, I must\r\nfirst load a dataset from base R, compute the correlation matrix using the cor()\r\nfunction, and then pass that matrix to the corrplot() function. The cor() makes\r\na table of correlations coefficients between the possible pairs of variables\r\nand the corrplot() function creates a nice visualization of the rounded results.\r\nAt least one LaTeX math expression (e.g., inline \\(alpha + beta = gamma\\) and a displayed equation).\r\nThis is an inline equation: if \\(e=mc^2\\) then:\r\nfor \\(m = 100\\), \\(c=299,792,458\\)\r\n\\(e = 100*299,792,458^2\\) is \\(=8.9875518e+18\\)\r\nAt least two executable R code chunks that:\r\nLoad a library or dataset.\r\n\r\n\r\n# Load a library and dataset\r\nlibrary(corrplot)\r\ndata(\"mtcars\")\r\nmyDF <- mtcars\r\nhead(myDF)\r\n\r\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\r\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\r\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\r\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\r\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\r\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\r\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\r\n\r\n&\r\nRun a simple analysis or generate a plot (e.g., summary statistics or ggplot2 chart).\r\n\r\n\r\n# Simple analysis and plot of mtcars dataset using corrplot package in r\r\n\r\n# Load a library and dataset\r\nlibrary(corrplot)\r\ndata(\"mtcars\")\r\nmyDF <- mtcars\r\nhead(myDF)\r\n\r\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\r\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\r\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\r\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\r\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\r\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\r\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\r\n\r\n# use cor() to create correlation matrix of mtcars variables\r\ncorResults<-cor(myDF,method = \"pearson\")\r\ncorResults<-round(corResults,2)\r\ncorResults\r\n\r\n       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\r\nmpg   1.00 -0.85 -0.85 -0.78  0.68 -0.87  0.42  0.66  0.60  0.48\r\ncyl  -0.85  1.00  0.90  0.83 -0.70  0.78 -0.59 -0.81 -0.52 -0.49\r\ndisp -0.85  0.90  1.00  0.79 -0.71  0.89 -0.43 -0.71 -0.59 -0.56\r\nhp   -0.78  0.83  0.79  1.00 -0.45  0.66 -0.71 -0.72 -0.24 -0.13\r\ndrat  0.68 -0.70 -0.71 -0.45  1.00 -0.71  0.09  0.44  0.71  0.70\r\nwt   -0.87  0.78  0.89  0.66 -0.71  1.00 -0.17 -0.55 -0.69 -0.58\r\nqsec  0.42 -0.59 -0.43 -0.71  0.09 -0.17  1.00  0.74 -0.23 -0.21\r\nvs    0.66 -0.81 -0.71 -0.72  0.44 -0.55  0.74  1.00  0.17  0.21\r\nam    0.60 -0.52 -0.59 -0.24  0.71 -0.69 -0.23  0.17  1.00  0.79\r\ngear  0.48 -0.49 -0.56 -0.13  0.70 -0.58 -0.21  0.21  0.79  1.00\r\ncarb -0.55  0.53  0.39  0.75 -0.09  0.43 -0.66 -0.57  0.06  0.27\r\n      carb\r\nmpg  -0.55\r\ncyl   0.53\r\ndisp  0.39\r\nhp    0.75\r\ndrat -0.09\r\nwt    0.43\r\nqsec -0.66\r\nvs   -0.57\r\nam    0.06\r\ngear  0.27\r\ncarb  1.00\r\n\r\n# use corrplot() to plot & visualize the results on heatmap\r\ncorrplot(corResults,type=\"upper\",order=\"hclust\",tl.col=\"black\",tl.srt=45)\r\n\r\n\r\n\r\nTask: 3 - Compile and Review\r\nKnit the document to HTML (or PDF) and save the output.\r\nCompare the source .Rmd file side‑by‑side with the rendered output.\r\nNote any formatting surprises or tips you discovered.\r\nHere is a screenshot of the code in rstudio:\r\n\r\nHere is a screenshot of the knitted output in HTML:\r\n\r\nA concluding reflection on your experience using R Markdown vs. writing plain reports\r\nIn conclusion, the experience from writing plain reports to using R Markdown is an interesting shift that offers significant advantages, despite a notable initial hurdle. The primary challenge lies in the steep learning curve associated with mastering R Markdown’s syntax, integration of code chunks, and understanding its various output formats and customization options. This initial time investment can be a deterrent for those accustomed to the immediate familiarity of traditional word processors.\r\nHowever, the benefits of practicing R Markdown ultimately far outweighs this initial difficulty. The fundamentals of programming ensure that narrative text, code, and results are integrated seamlessly, leading to reports that are fully reproducible, dynamic, and less prone to manual errors. The ability to generate professional quality outputs in multiple formats like, PDF, HTML, and Word from a single source file greatly enhances efficiency and consistency as well. While the initial learning curve requires commitment, the resulting automation, reproducibility, and flexibility transforms the reporting process, making R Markdown a great choice for data science and analytical driven communication.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-11-05-module-11-assignment/debugging.png?raw=true",
    "last_modified": "2025-11-10T14:05:28-05:00",
    "input_file": "module-12-assignment.knit.md"
  },
  {
    "path": "posts/2025-11-05-module-11-assignment/",
    "title": "Module 11 Assignment",
    "description": "Debugging and Defensive Programming in R",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-11-05",
    "categories": [],
    "contents": "\r\nHere are my debugging screenshots:\r\n1st\r\n\r\n2nd:\r\n\r\n\r\n\r\n#Module #11 post for my LIS4370 blog. Welcome!\r\n\r\n# Below is a function intended to flag rows of a numeric matrix x that are\r\n# outliers in every column according to the Tukey rule.\r\n# It contains a deliberate bug:\r\n\r\ntukey_multiple <- function(x) {\r\n  outliers <- array(TRUE, dim = dim(x))\r\n  for (j in 1:ncol(x)) {\r\n    outliers[, j] <- outliers[, j] && tukey.outlier(x[, j])\r\n  }\r\n  outlier.vec <- vector(\"logical\", length = nrow(x))\r\n  for (i in 1:nrow(x)) {\r\n    outlier.vec[i] <- all(outliers[i, ])\r\n  }\r\n  return(outlier.vec)\r\n}\r\n\r\n# Task 1 - Reproduce the Error\r\n\r\n# In R, create a test matrix and run the function:\r\nset.seed(123)\r\ntest_mat <- matrix(rnorm(50), nrow = 10)\r\n\r\n# Capture the exact error message you see.\r\n\r\ntukey_multiple(test_mat)\r\n\r\nError in outliers[, j] && tukey.outlier(x[, j]): 'length = 10' in coercion to 'logical(1)'\r\n\r\n# Task 2 - Diagnose the Bug\r\n#traceback()\r\n#debug(tukey_multiple)\r\n#tukey_multiple(test_mat)\r\n\r\n# Screenshot of process/output\r\n\r\n# Reflect on why using && inside the loop causes the failure.\r\n# (Recall that && only returns a single TRUE/FALSE for the first element,\r\n# whereas you need element‑wise comparison.)\r\n\r\n# & is vectorized and && is not. && only treats a vector as a scalar object and\r\n# only evaluates the first element and && will evaluate all elements in vectors.\r\n\r\n# Task 3 - Fix the Code\r\n\r\n# Edit the function so that the logical operation is applied element‑wise.\r\n# Specifically, replace the buggy line with the correct operator.\r\n\r\n# Corrected inside the loop:\r\n# outliers[, j] <- outliers[, j] & tukey.outlier(x[, j])\r\n\r\ncorrected_tukey <- function(x) {\r\n  outliers <- array(TRUE, dim = dim(x))\r\n  for (j in seq_len(ncol(x))) {\r\n    outliers[, j] <- outliers[, j] & tukey.outlier(x[, j])\r\n  }\r\n  outlier.vec <- logical(nrow(x))\r\n  for (i in seq_len(nrow(x))) {\r\n    outlier.vec[i] <- all(outliers[i, ])\r\n  }\r\n  outlier.vec\r\n}\r\n\r\n# Task 4 - Validate Your Fix\r\n\r\n# Re‑run your corrected function on test_mat and verify it returns a\r\n# logical vector of length 10 without error:\r\ncorrected_tukey(test_mat)\r\n\r\nError in tukey.outlier(x[, j]): could not find function \"tukey.outlier\"\r\n\r\n#traceback()\r\n#debug(tukey_multiple)\r\n#tukey_multiple(test_mat)\r\n\r\n# Screenshot of process/output\r\n\r\n# remove the faulty function & Fix the Code\r\n\r\n# Edit the function so that tukey.outlier() is removed.\r\ncorrected_tukey <- function(x) {\r\n  outliers <- array(TRUE, dim = dim(x))\r\n  for (j in seq_len(ncol(x))) {\r\n    outliers[, j] <- outliers[, j] & x[, j]\r\n  }\r\n  outlier.vec <- logical(nrow(x))\r\n  for (i in seq_len(nrow(x))) {\r\n    outlier.vec[i] <- all(outliers[i, ])\r\n  }\r\n  outlier.vec\r\n}\r\n\r\n# Re‑run your corrected function on test_mat and verify it returns a\r\n# logical vector of length 10 without error:\r\ncorrected_tukey(test_mat)\r\n\r\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\r\n\r\nHere is a link to my GitHub repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-11-Debugging\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-11-05-module-11-assignment/debugging.png?raw=true",
    "last_modified": "2025-11-05T08:55:57-05:00",
    "input_file": "module-11-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-27-module-10-assignment/",
    "title": "Module 10 Assignment",
    "description": "Building your own R package",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-27",
    "categories": [],
    "contents": "\r\n\r\n\r\n# Module 10 assignment\r\n\r\n# Task 1 - Initialize Your Package Skeleton\r\n\r\n# In R, run:\r\nlibrary(devtools)\r\n#create(\"Friedman\")\r\n#This creates a folder Friedman/ with subfolders (R/, man/, etc.) and a default DESCRIPTION.\r\n\r\n# Task 2 - Edit the DESCRIPTION File\r\n\r\n#Open Friedman/DESCRIPTION and update the fields:\r\n#Package: your package name (keep Friedman or rename).\r\n#Title: concise one‑line summary.\r\n#Version: start with 0.0.0.9000.\r\n#Authors@R: list yourself and any collaborators.\r\n#Description: one paragraph describing functionality.\r\n#Depends: specify R (>= 3.1.2) only.\r\n#Imports: list packages you will use (e.g., ggplot2, dplyr).\r\n#License: choose (e.g., CC0).\r\n#LazyData: set to true if you include data sets.\r\n\r\n#Optionally add:\r\n\r\n#URL: link to GitHub repo or website.\r\n#BugReports: GitHub issues URL.\r\n#Suggests: packages for testing and examples.\r\n\r\n# Task 3 - Verify and Build\r\n\r\n#From your package root, run:\r\n#check(\"Friedman\")\r\n#build(\"Friedman\")\r\n# Fix any DESCRIPTION or dependency warnings.\r\n\r\n# Task 4 - Publish to GitHub\r\n\r\n#Initialize a Git repo in Friedman/, commit all files.\r\n#Create a new GitHub repository named Friedman and push your local repo.\r\n#Ensure DESCRIPTION and minimal files (R/, NAMESPACE) are present in GitHub.\r\n\r\n\r\nI propose Base R Visualization Package Idea: simplebaseplots This package will provide simplified wrappers around base R’s powerful plotting functions (plot(), hist(), boxplot()) to make them consistent and easy to use for beginners.\r\nThe R package, which can be named basicrplots, provides a simple set of functions for generating common statistical visualizations (scatterplot, histogram, boxplot) using only Base R graphics functions. The goal of this package is to offer a lightweight alternative to more complex visualization libraries, making it ideal for beginners learning R, instructors teaching fundamental data visualization concepts without external dependencies, or scenarios where minimal package overhead is desired. The core functions will abstract away some of the repetitive setup code required for standard Base R plots, allowing users to quickly generate publication-ready simple graphs with consistent styling and clear default labeling.\r\nThe basicrplots package provides three core functions that generate essential statistical graphics exclusively using Base R capabilities:\r\nbasic_scatterplot(x, y, …): Creates a standard X-Y scatterplot. It accepts two numeric vectors and optional parameters for a custom title, axis labels, and point color. It uses solid points (pch = 19) by default.\r\nbasic_histogram(x, …): Generates a frequency histogram for a single numeric vector. Users can customize the plot title, x-axis label, and the fill color of the bars, offering a quick visual summary of data distribution.\r\nbasic_boxplot(formula, data, …): Produces a box-and-whisker plot. This function is flexible, allowing users to input either a single numeric vector or a formula (y ~ group) to compare distributions across different categories within a data frame. It supports customizations for title, y-axis label, and box color.\r\nThis is my descriptions file:\r\n\r\nI verified that the package was created successfully and that errors were handled.\r\n\r\nThen I confirmed that the package was pushed to a new github repo.\r\n\r\nHere is a link to my github repo:\r\n\r\nhttps://github.com/skywalshUSF/Friedman/tree/main\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-10-27-module-10-assignment/desc.png?raw=true",
    "last_modified": "2025-10-27T14:28:12-04:00",
    "input_file": "module-10-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-22-module-9-assignment/",
    "title": "Module 9 Assignment",
    "description": "Visualization",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-22",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-09-Visualization-with-ggplot2\r\n\r\n\r\n#Module #9 post for my LIS4370 blog. Welcome!\r\n\r\n# Choose one dataset from the Rdatasets collection. Load it into R with:\r\n# data(\"DatasetName\",package = \"PackageName\")\r\n# head(DatasetName)\r\ndata(\"mtcars\", package = \"datasets\")\r\nhead(mtcars)\r\n\r\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\r\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\r\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\r\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\r\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\r\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\r\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\r\n\r\n# Task 1 - Base R Graphics\r\n# Create at least two plots using base R functions.\r\n\r\n# Scatter plot\r\nplot(mtcars$mpg, main=\"Base R 'mtcars' data set scatter plot: mpg\", xlab=\"wt\", ylab=\"mpg\", pch=19, col=\"darkblue\")\r\n\r\n\r\n# Histogram\r\nhist(mtcars$mpg, main = \"Base R 'mtcars histogram of miles per gallon\", xlab = \"mpg\", col=\"lightblue\", border=\"black\")\r\n\r\n\r\n# Task 2 - Lattice Graphics\r\n# Use the lattice package to produce conditioned or multivariate plots\r\nlibrary(lattice)\r\n\r\n# Conditional scatter plot (small multiples)\r\nxyplot(mpg ~ wt|factor(cyl), data = mtcars, main=\"Lattice: mpg vs. wt by number of cylinders\")\r\n\r\n\r\n# Box-and-whisker plot\r\nbwplot(mpg ~ factor(cyl), data = mtcars, main = \"Lattice: miles per gallon by cylinder\")\r\n\r\n\r\n# Task 3 - ggplot2\r\n# Use ggplot2's grammar of graphics to create layered visuals.\r\nlibrary(ggplot2)\r\n\r\n# Scatter plot with smoothing\r\nggplot(mtcars, aes(x = wt, y = mpg, color=factor(cyl))) + geom_point() + geom_smooth(method = \"lm\") + labs(title = \"ggplot2: mpg vs. wt with trend by cyl\")\r\n\r\n\r\n# Faceted Histogram\r\nggplot(mtcars, aes(mpg)) + geom_histogram(binwidth = 1) + facet_wrap(~ cyl) + labs(title = \"ggplot2: mpg distribution by cyl\")\r\n\r\n\r\n# Discussion\r\n# On your blog, embed your three visualizations (one from each system) and address:\r\n\r\n\r\n# How does the syntax and workflow differ between base, lattice, and ggplot2?\r\n\r\n# For base graphics, the workflow is incremental. You start with a highly\r\n# advanced plotting function called plot() to create the base plot, and then use\r\n# separate arguments like main, xlab, and ylab to add additional elements that\r\n# will be contained inside the plot. The syntax in base graphics is function\r\n# based, meaning it uses many separate, simple functions, such as plot() and\r\n# hist(). Plot parameters are passed directly as arguments within these\r\n# functions. For the lattice library, the workflow is indicative. You specify\r\n# all the plot components within a single function call. This library also uses\r\n# a highly advanced function called xyplot(). The syntax in lattice is based on\r\n# a variety of formulas. The main functions, like xyplot() and bwplot(), use a\r\n# formula to define the variables of a y variable predicted by an x variable.\r\n# In ggplot2, the workflow is more integrated. You build the plot in layers,\r\n# assign it to an object, and then add, remove, or modify layers. This\r\n# integration makes it easier to create complex plots and saves elements that\r\n# are used multiple times. The syntax in ggplot2 is simply conditional because\r\n# parameters are passed as arguments, and the variables used in this library are\r\n# often paired with function arguments for customization.\r\n\r\n\r\n# Which system gave you the most control or produced the most\r\n# “publication-quality” output with minimal code?\r\n\r\n# After comparing the workflow and syntax of the three R graphics systems, I\r\n# found that ggplot2 offered the most control and produced publication-quality\r\n# output efficiently. Its layered structure allowed for extra control over every\r\n# plot element, from modifying layers and scales to setting labels. By adding new\r\n# layers via concatenation, I was able to build useful plots, as shown in my\r\n# task 3 code.\r\n\r\n\r\n# Any challenges or surprises you encountered when switching between systems?\r\n\r\n# When switching between R graphics systems, I have encountered both challenges\r\n# and surprises. When switching to or from Base Graphics, I couldn't undo a plot.\r\n# Once I start a plot, I cannot go back to modify an earlier element. Also, I was\r\n# surprised to see how simple and fast it was to create a scatter plot with the\r\n# plot() function. When switching to or from lattice, I found myself needing to\r\n# know less common Base graphics syntax, like the | for given, which made\r\n# comprehending the xyplot() function a bit more difficult. I was, however,\r\n# surprised at how efficient and concise lattice’s formula syntax can be when I\r\n# go to do a simple conditional plot. Finally, switching to or from ggplot2\r\n# challenged my thinking because of how it handles aesthetic mappings with the\r\n# aes() function, which differs from how I am used to understanding standard R\r\n# evaluation in Base Graphics. I was surprised at how the legend in my ggplot2\r\n# scatter plot with smoothing automatically appeared in the visual without even\r\n# needing a legend argument.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-10-22-module-9-assignment/datavis.jpg?raw=true",
    "last_modified": "2025-10-22T10:55:26-04:00",
    "input_file": "module-9-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-13-module-8-assignment/",
    "title": "Module 8 Assignment",
    "description": "Input/Output, String Manipulation, and the plyr Package",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-13",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-08-Input-Output-String-Manipulation-r\r\n\r\n\r\n#Module #8 post for my LIS4370 blog. Welcome!\r\n\r\n# Task 1 - Import Assignment 6 Data\r\n\r\n# Place the Assignment 6 dataset (tab‑ or space‑delimited) on your computer and\r\n# In R, read it into a data frame\r\nx <- read.table(\"C:/RProgrammingFall2025WalshSkylar/Assignments/Assignment-08-Input-Output-String-Manipulation-r/Assignment 6 Dataset.txt\", header = T, sep = \",\")\r\nx\r\n\r\n        Name Age    Sex Grade\r\n1       Raul  25   Male    80\r\n2     Booker  18   Male    83\r\n3      Lauri  21 Female    90\r\n4     Leonie  21 Female    91\r\n5    Sherlyn  22 Female    85\r\n6    Mikaela  20 Female    69\r\n7    Raphael  23   Male    91\r\n8       Aiko  24 Female    97\r\n9   Tiffaney  21 Female    78\r\n10    Corina  23 Female    81\r\n11 Petronila  23 Female    98\r\n12    Alecia  20 Female    87\r\n13   Shemika  23 Female    97\r\n14    Fallon  22 Female    90\r\n15   Deloris  21 Female    67\r\n16    Randee  23 Female    91\r\n17     Eboni  20 Female    84\r\n18   Delfina  19 Female    93\r\n19 Ernestina  19 Female    93\r\n20      Milo  19   Male    67\r\n\r\n# Load plyr and compute the mean of Grade by Sex\r\nlibrary(plyr)\r\ngender_mean <- ddply(x,\"Sex\",transform, Grade.Average=mean(Grade))\r\ngender_mean\r\n\r\n        Name Age    Sex Grade Grade.Average\r\n1      Lauri  21 Female    90       86.9375\r\n2     Leonie  21 Female    91       86.9375\r\n3    Sherlyn  22 Female    85       86.9375\r\n4    Mikaela  20 Female    69       86.9375\r\n5       Aiko  24 Female    97       86.9375\r\n6   Tiffaney  21 Female    78       86.9375\r\n7     Corina  23 Female    81       86.9375\r\n8  Petronila  23 Female    98       86.9375\r\n9     Alecia  20 Female    87       86.9375\r\n10   Shemika  23 Female    97       86.9375\r\n11    Fallon  22 Female    90       86.9375\r\n12   Deloris  21 Female    67       86.9375\r\n13    Randee  23 Female    91       86.9375\r\n14     Eboni  20 Female    84       86.9375\r\n15   Delfina  19 Female    93       86.9375\r\n16 Ernestina  19 Female    93       86.9375\r\n17      Raul  25   Male    80       80.2500\r\n18    Booker  18   Male    83       80.2500\r\n19   Raphael  23   Male    91       80.2500\r\n20      Milo  19   Male    67       80.2500\r\n\r\n# Write the grouped means to a text file\r\nwrite.table(gender_mean, \"gender_mean.txt\",sep=\",\",row.names = F)\r\n\r\n# Task 2 - Filter Names Containing \"i\"\r\n\r\n# Convert the data (if not already) to a data frame (see above).\r\n# Select rows where Name contains “i” or “I”\r\ni_students <- subset(x,grepl(\"[iI]\",x$Name))\r\ni_students\r\n\r\n        Name Age    Sex Grade\r\n3      Lauri  21 Female    90\r\n4     Leonie  21 Female    91\r\n6    Mikaela  20 Female    69\r\n8       Aiko  24 Female    97\r\n9   Tiffaney  21 Female    78\r\n10    Corina  23 Female    81\r\n11 Petronila  23 Female    98\r\n12    Alecia  20 Female    87\r\n13   Shemika  23 Female    97\r\n15   Deloris  21 Female    67\r\n17     Eboni  20 Female    84\r\n18   Delfina  19 Female    93\r\n19 Ernestina  19 Female    93\r\n20      Milo  19   Male    67\r\n\r\n# Extract just the names and write them to a CSV\r\nwrite.csv(i_students$Name, file = \"i_students.csv\", row.names = F, quote = F)\r\n\r\n# Task 3- Export Filtered Dataset\r\n\r\n# Save the full filtered data frame to a CSV\r\nwrite.csv(i_students, file = \"i_students_full.csv\", row.names = F)\r\n\r\n# Confirm the files gender_mean.txt, i_students.csv, and i_students_full.csv\r\n# exist in your working directory.\r\n\r\n# choose files from working directory, read/scan and test output\r\ngender_mean_test <- read.table(\"C:/RProgrammingFall2025WalshSkylar/gender_mean.txt\", header = TRUE, stringsAsFactors = FALSE,sep = \",\")\r\nhead(gender_mean_test)\r\n\r\n      Name Age    Sex Grade Grade.Average\r\n1    Lauri  21 Female    90       86.9375\r\n2   Leonie  21 Female    91       86.9375\r\n3  Sherlyn  22 Female    85       86.9375\r\n4  Mikaela  20 Female    69       86.9375\r\n5     Aiko  24 Female    97       86.9375\r\n6 Tiffaney  21 Female    78       86.9375\r\n\r\ni_students_test <- read.table(\"C:/RProgrammingFall2025WalshSkylar/i_students.csv\", header = TRUE, stringsAsFactors = FALSE,sep = \",\")\r\nhead(i_students_test)\r\n\r\n         x\r\n1    Lauri\r\n2   Leonie\r\n3  Mikaela\r\n4     Aiko\r\n5 Tiffaney\r\n6   Corina\r\n\r\ni_students_full_test <- read.table(\"C:/RProgrammingFall2025WalshSkylar/i_students_full.csv\", header = TRUE, stringsAsFactors = FALSE,sep = \",\")\r\nhead(i_students_full_test)\r\n\r\n      Name Age    Sex Grade\r\n1    Lauri  21 Female    90\r\n2   Leonie  21 Female    91\r\n3  Mikaela  20 Female    69\r\n4     Aiko  24 Female    97\r\n5 Tiffaney  21 Female    78\r\n6   Corina  23 Female    81\r\n\r\n# To begin data manipulation, the read.table() function will be used to import\r\n# data from a file into a data frame, designated as 'x', where lines are records\r\n# and fields are variables. The 'x' data frame can be used to group specific\r\n# records. This 'x' data frame is then processed using the ddply() function from\r\n# the plyr package, which allows for grouping and selection of rows or columns.\r\n# The results are stored in a new object named 'y' that includes a new column\r\n# named 'Grade.Average' that holds the mean of Grade grouped by Sex. The\r\n# write.table() function is used to write data from a data frame into a text\r\n# file and store it in the working directory. The subset() function allows the\r\n# program to filter character data in strings with regular expressions using\r\n# grepl(). All of the records in the 'i_students' data frame can be exported to\r\n# a .csv file in the working directory using the write.csv() function.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-10-13-module-8-assignment/r-string.jpg?raw=true",
    "last_modified": "2025-10-13T15:05:37-04:00",
    "input_file": "module-8-assignment.knit.md"
  },
  {
    "path": "posts/2025-10-08-module-7-assignment/",
    "title": "Module 7 Assignment",
    "description": "R Object: S3 vs. S4",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-10-08",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-07-R-Object_S3_vs._S4\r\n\r\n\r\n#Module #7 post for my LIS4370 blog. Welcome!\r\n\r\n\r\n# Task 1- Choose or Download Data\r\n# Load an existing dataset (e.g., data(\"mtcars\")) or download/create your own.\r\n# Show the first few rows with head() and describe its structure with str().\r\n\r\n# Load the \"iris\" dataset and store to an object called \"iris_df\"\r\ndata(\"iris\")\r\niris_df <- iris\r\n\r\n# Print the first six rows of the \"iris_df\" object\r\nhead(iris_df)\r\n\r\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r\n1          5.1         3.5          1.4         0.2  setosa\r\n2          4.9         3.0          1.4         0.2  setosa\r\n3          4.7         3.2          1.3         0.2  setosa\r\n4          4.6         3.1          1.5         0.2  setosa\r\n5          5.0         3.6          1.4         0.2  setosa\r\n6          5.4         3.9          1.7         0.4  setosa\r\n\r\n# Explore the structure of the \"iris_df\" object\r\nstr(iris_df)\r\n\r\n'data.frame':   150 obs. of  5 variables:\r\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\r\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\r\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\r\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\r\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n\r\n# Task 2 - Test Generic Functions\r\n\r\n# Pick one or more base generic functions (e.g., print(), summary(), plot()).\r\n# Apply them to your dataset or an object derived from it.\r\n# If a generic does *not* dispatch on your object, explain *why*\r\n# (e.g., no method defined for that class).\r\n\r\n# Use the class() function to determine an object's class\r\nclass(iris_df)\r\n\r\n[1] \"data.frame\"\r\n\r\n# Use the str() function to show variables and object types, and show the inner\r\n# structure of an R object\r\nstr(iris_df)\r\n\r\n'data.frame':   150 obs. of  5 variables:\r\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\r\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\r\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\r\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\r\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\r\n\r\n# Use the summary() function to provide a concise summary of an R object, and\r\n# display the object variable statistics\r\nsummary(iris_df)\r\n\r\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \r\n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \r\n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \r\n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \r\n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \r\n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \r\n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \r\n       Species  \r\n setosa    :50  \r\n versicolor:50  \r\n virginica :50  \r\n                \r\n                \r\n                \r\n\r\n# Use the length() function to return the length of an object\r\nlength(iris_df)\r\n\r\n[1] 5\r\n\r\n# Task 3 - Explore S3 vs. S4\r\n\r\n# Create an S3 object example:\r\ns3_obj <- list(computer = \"PC\", year = 1985, price = 350)\r\n\r\n# Set the class of an object as an attribute\r\nclass(s3_obj) <- \"computer_s3\"\r\nclass(s3_obj)\r\n\r\n[1] \"computer_s3\"\r\n\r\n# Use the print() function dispatch to display S3 object\r\nprint(s3_obj)\r\n\r\n$computer\r\n[1] \"PC\"\r\n\r\n$year\r\n[1] 1985\r\n\r\n$price\r\n[1] 350\r\n\r\nattr(,\"class\")\r\n[1] \"computer_s3\"\r\n\r\n# Use the str() function dispatch to display the inner structure of the S3\r\n# object.\r\nstr(s3_obj)\r\n\r\nList of 3\r\n $ computer: chr \"PC\"\r\n $ year    : num 1985\r\n $ price   : num 350\r\n - attr(*, \"class\")= chr \"computer_s3\"\r\n\r\n# Create an S4 class and object example:\r\nsetClass(\"computer_s4\", slots = c(computer = \"character\", year = \"numeric\", price = \"numeric\"))\r\n\r\n# Embody a new S4 object with the use of the new() function and assigning an\r\n# initial value to a variable.\r\ns4_obj <- new(\"computer_s4\", computer = \"Laptop\", year = 2025, price = 2000)\r\nclass(s4_obj)\r\n\r\n[1] \"computer_s4\"\r\nattr(,\"package\")\r\n[1] \".GlobalEnv\"\r\n\r\n# Use the print() function dispatch to display S4 object\r\nprint(s4_obj)\r\n\r\nAn object of class \"computer_s4\"\r\nSlot \"computer\":\r\n[1] \"Laptop\"\r\n\r\nSlot \"year\":\r\n[1] 2025\r\n\r\nSlot \"price\":\r\n[1] 2000\r\n\r\n# Use the str() function dispatch to display the inner structure of the S4\r\n# object.\r\nstr(s4_obj)\r\n\r\nFormal class 'computer_s4' [package \".GlobalEnv\"] with 3 slots\r\n  ..@ computer: chr \"Laptop\"\r\n  ..@ year    : num 2025\r\n  ..@ price   : num 2000\r\n\r\n# Discussion Questions\r\n\r\n# On your blog, answer the following:\r\n\r\n# How can you tell whether an object uses S3 or S4?\r\n# (Which functions inspect its class system?)\r\n\r\n# I can tell whether an object uses S3 or S4 class system object structure by\r\n# calling functions and passing the object as an argument to get informative\r\n# output about the object, its class, and structure. Some of the functions that\r\n# inspect an object's class system are the class() function that displays the\r\n# class name for S3 objects and formal class name for S4. Also, the str() function\r\n# is helpful for inspecting an object's class system because it lists it in the\r\n# output. The print() function will also list the object's type or class.\r\n\r\n# How do you determine an object’s underlying type (e.g., integer vs. list)?\r\n\r\n# I determined an object's underlying type by using the str() function, which\r\n# lists the object's type in the output. If the object is an integer or a list\r\n# type object, it will say so, otherwise, if the object is an S4 object, the str()\r\n# function output will state that it's a formal class type and name the class.\r\n# The print() function will also list the object's type or class.\r\n\r\n# What is a generic function in R?\r\n\r\n# A generic function is central to R's S3 OOP system, enabling a single\r\n# function call to behave differently based on the class of the object.\r\n# When called, R selects the specific method matching the object's class\r\n# (or a default if none is found). In S3, this method dispatch uses the\r\n# first argument's class. In contrast, R's S4 system allows for multiple\r\n# dispatch, which considers the classes of several arguments.\r\n\r\n\r\n# What are the principal differences between S3 and S4\r\n# (e.g., method definition, formal class declarations)?\r\n\r\n# The key differences between R's S3 and S4 object systems are their format and\r\n# structure. S3 objects are informal; a simple list or vector becomes an S3\r\n# object just by assigning a class attribute to it. In contrast, S4 objects are\r\n# much more formal and structured: their classes must be defined beforehand\r\n# using the setClass() function, which specifies the class name and its data\r\n# slots. This means S4 requires formal class definitions before an object can be\r\n# created, unlike the more flexible S3 system.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-10-08-module-7-assignment/OOP.jpg?raw=true",
    "last_modified": "2025-10-08T15:23:40-04:00",
    "input_file": "module-7-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-29-module-6-assignment/",
    "title": "Module 6 Assignment",
    "description": "Doing Math in R Part 2",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-29",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-06-Doing-Math-In-R-Part-2\r\n\r\n\r\n#Module #6 post for my LIS4370 blog. Welcome!\r\n\r\n# Task 1- Matrix Addition & Subtraction\r\n\r\n#In R, define:\r\n# Create a matrix using the matrix() function for objects A and B.\r\n# Both A and B will each contain a matrix that holds two rows and two columns.\r\n# Having four elements in all, in two columns, implies two rows:\r\nA <- matrix(c(2, 0, 1, 3), ncol = 2)\r\nB <- matrix(c(5, 2, 4, -1), ncol = 2)\r\n\r\n#Then:\r\n#Compute A + B and display the result.\r\n# m1 is a defined object that will perform addition on two separate matrix objects:\r\nm1 <- A + B\r\n# Here is what the matrix looks like:\r\nm1\r\n\r\n     [,1] [,2]\r\n[1,]    7    5\r\n[2,]    2    2\r\n\r\n# Each element in matrix A is added to the corresponding element in matrix B.\r\n# The result is a new matrix of the same dimensions as the original matrices,\r\n# but different values.\r\n\r\n#Compute A - B and display the result.\r\n# m2 is a defined object that will perform subtraction on two separate matrix\r\n# objects:\r\nm2 <- A - B\r\n# Here is what the matrix looks like:\r\nm2\r\n\r\n     [,1] [,2]\r\n[1,]   -3   -3\r\n[2,]   -2    4\r\n\r\n# Each element in matrix A is subtracted by the element in the same row and\r\n# column of matrix B. The result is a new matrix of the same dimensions as the\r\n# original matrices, but different values.\r\n\r\n# Task 2- Create a Diagonal Matrix\r\n# The diag() function creates a diagonal square matrix.\r\n#Use diag() to build a 4×4 matrix with diagonal entries 4, 1, 2, 3:\r\nD <- diag(c(4, 1, 2, 3))\r\n# Here is the result\r\nD\r\n\r\n     [,1] [,2] [,3] [,4]\r\n[1,]    4    0    0    0\r\n[2,]    0    1    0    0\r\n[3,]    0    0    2    0\r\n[4,]    0    0    0    3\r\n\r\n# The diag() function helped me construct a diagonal matrix and add matrix values\r\n# diagonally. Since the argument inside of the diag() function was a vector, and\r\n# because the first cell of a matrix starts on the top left, the order in which\r\n# the values of the vector will be displayed is from top left to bottom right.\r\n\r\n# Task 3- Construct a Custom 5×5 Matrix\r\n#Generate this matrix:\r\n#  [,1] [,2] [,3] [,4] [,5]\r\n#[1,]    3    1    1    1    1\r\n#[2,]    2    3    0    0    0\r\n#[3,]    2    0    3    0    0\r\n#[4,]    2    0    0    3    0\r\n#[5,]    2    0    0    0    3\r\n#Hint: combine diag() with cbind() or matrix().\r\n# Define a matrix for the first row and column elements\r\nC <- matrix(cbind(c(1, 2, 2, 2, 2),c(1, 0, 0, 0, 0),c(1, 0, 0, 0, 0),c(1, 0, 0, 0, 0),c(1, 0, 0, 0, 0)), nrow = 5)\r\nC\r\n\r\n     [,1] [,2] [,3] [,4] [,5]\r\n[1,]    1    1    1    1    1\r\n[2,]    2    0    0    0    0\r\n[3,]    2    0    0    0    0\r\n[4,]    2    0    0    0    0\r\n[5,]    2    0    0    0    0\r\n\r\n# The matrix() function was able to take a set of five vectors and combine them\r\n# into a single vector as a data argument. I then specified the number of rows to\r\n# be five to define the dimensions of the first matrix.\r\n\r\n# Define a second to add to the first matrix.\r\nD <- diag(c(2,3,3,3,3))\r\nD\r\n\r\n     [,1] [,2] [,3] [,4] [,5]\r\n[1,]    2    0    0    0    0\r\n[2,]    0    3    0    0    0\r\n[3,]    0    0    3    0    0\r\n[4,]    0    0    0    3    0\r\n[5,]    0    0    0    0    3\r\n\r\n# With my first matrix created, a diagonal matrix can now be created. The\r\n# values that are within the vector argument of diag() in matrix D depended on\r\n# the row and column numbers from matrix C.\r\n\r\n\r\n# Add the two matrices together\r\nresult <- C + D\r\nresult\r\n\r\n     [,1] [,2] [,3] [,4] [,5]\r\n[1,]    3    1    1    1    1\r\n[2,]    2    3    0    0    0\r\n[3,]    2    0    3    0    0\r\n[4,]    2    0    0    3    0\r\n[5,]    2    0    0    0    3\r\n\r\n# Once both matrix C and matrix D have had the same dimensions, I was able to\r\n# define an object called result add the two matrices using the + operator. This\r\n# will add a cell position in one matrix to its corresponding cell position in the\r\n# other matrix.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-09-29-module-6-assignment/matrix_math.png?raw=true",
    "last_modified": "2025-09-29T15:08:27-04:00",
    "input_file": "module-6-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-22-module-5-assignment/",
    "title": "Module 5 Assignment",
    "description": "Doing Math in R",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-22",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-05-Doing-Math-in-R-Part-1\r\n\r\n\r\n#Module #5 post for my LIS4370 blog. Welcome!\r\n\r\n# Task 1- Create the matrices\r\n\r\n# In R, define\r\nA <- matrix(1:100, nrow = 10)\r\nB <- matrix(1:1000, nrow = 10)\r\n\r\n# Task 2 - Inspect dimensions\r\n\r\n# Verify whether each matrix is square\r\ndim(A) # should be 10 x 10\r\n\r\n[1] 10 10\r\n\r\ndim(B) # 10 x 100 - not square\r\n\r\n[1]  10 100\r\n\r\n# Task 3 - Compute inverse and determinant\r\n\r\n# Use solve() and det(); handle errors for non-square or singular matrices:\r\n\r\n# For A\r\ninvA <- tryCatch(solve(A), error = function(e) print(e))\r\n\r\n<simpleError in solve.default(A): Lapack routine dgesv: system is exactly singular: U[6,6] = 0>\r\n\r\ndetA <- det(A)\r\n\r\n# For B, use tryCatch to capture errors\r\ninvB <- tryCatch(solve(B), error = function(e) print(e))\r\n\r\n<simpleError in solve.default(B): 'a' (10 x 100) must be square>\r\n\r\ndetB <- tryCatch(det(B), error = function(e) print(e))\r\n\r\n<simpleError in determinant.matrix(x, logarithm = TRUE, ...): 'x' must be a square matrix>\r\n\r\n# Task 4 - Document your results\r\n\r\n# R code is shown above for creating A and B, and for computing invA, detA,\r\n# invB, and detB\r\n\r\n# Output or error messages for each operation.\r\n\r\n# A brief explanation:\r\n\r\n# Why solve(A) and det(A) work.\r\n\r\n# In my operation test, solve(A) did not work. Instead, I got an error message\r\n# stating that the object 'invA' was not found. When I created the first matrix\r\n# A, and applied the solve() function, the output turned out to be a message\r\n# stating that system is exactly singular: U[6,6] = 0. This is because not all\r\n# square matrices have an inverse matrix. If the determinant of the matrix is\r\n# zero, which was the output for the determinant of matrix A (detA), then it\r\n# will not have an inverse, and the matrix is said to be singular.\r\n\r\n# Even though det(A) successfully printed out a value, the output of zero\r\n# indicates that this matrix is not non-singular and there is no inverse\r\n# solution in matrix A.\r\n\r\n# Why operations on B fail (non‑square matrix).\r\n\r\n# The operations fail to work on matrix B because it does not contain an equal\r\n# amount of rows and columns on its dimensions. The dimensions of matrix B are\r\n# 10:100, which is a non-square matrix that does not have any inverse solutions\r\n# or estimated regression parameters. This means that neither variables ('invB'\r\n# and 'detB') nor solve(B) and det(B) will generate a result.\r\n\r\n# Any notes on numeric stability or performance.\r\n\r\n# The notes that I have on numeric stability include what determinants are and\r\n# how they can be used to find the inverse of a matrix. This helps to understand\r\n# how to compute the most accurate results according to the appropriate use of\r\n# matrix math, along with having proper runtime and syntax in computer programs\r\n# without any errors to perform the requested operations correctly. This should\r\n# be important to remember whenever we create a visual that describes a\r\n# relationship between quantities that change at a constant rate, like a\r\n# straight line plotted on a graph.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-09-22-module-5-assignment/matrix.png?raw=true",
    "last_modified": "2025-09-22T14:57:15-04:00",
    "input_file": "module-5-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-15-module-4-assignment/",
    "title": "Module 4 Assignment",
    "description": "Programming Structure in R",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-15",
    "categories": [],
    "contents": "\r\nHere is a link to my github repo:\r\nhttps://github.com/skywalshUSF/RProgrammingFall2025WalshSkylar/tree/main/Assignments/Assignment-04-Programming-Structure\r\n\r\n\r\n#Module #4 post for my LIS4370 blog. Welcome!\r\n\r\n#Task 1 - Data Preparation and Cleaning\r\n\r\n#Define each vector in R, converting categorical strings to numeric codes\r\n#(bad=1,good=0) (low=0,high=1) and handling NA's appropriately:\r\n\r\nFrequency<-c(0.6,0.3,0.4,0.4,0.2,0.6,0.3,0.4,0.9,0.2)\r\nBloodPressure<-c(103,87,32,42,59,109,78,205,135,176)\r\nFirstAssess<-c(1,1,1,1,0,0,0,0,NA,1) ##(bad=1,good=0)\r\nSecondAssess<-c(0,0,1,1,0,0,1,1,1,1) ##(low=0,high=1)\r\nFinalDecision<-c(0,1,0,1,0,1,0,1,1,1) ##(low=0,high=1)\r\n\r\ndf_hosp<-data.frame(Frequency,BloodPressure,FirstAssess,SecondAssess,FinalDecision,stringsAsFactors = FALSE)\r\n\r\n#Inspect and handle NA's\r\nsummary(df_hosp)\r\n\r\n   Frequency    BloodPressure     FirstAssess      SecondAssess\r\n Min.   :0.20   Min.   : 32.00   Min.   :0.0000   Min.   :0.0  \r\n 1st Qu.:0.30   1st Qu.: 63.75   1st Qu.:0.0000   1st Qu.:0.0  \r\n Median :0.40   Median : 95.00   Median :1.0000   Median :1.0  \r\n Mean   :0.43   Mean   :102.60   Mean   :0.5556   Mean   :0.6  \r\n 3rd Qu.:0.55   3rd Qu.:128.50   3rd Qu.:1.0000   3rd Qu.:1.0  \r\n Max.   :0.90   Max.   :205.00   Max.   :1.0000   Max.   :1.0  \r\n                                 NA's   :1                     \r\n FinalDecision\r\n Min.   :0.0  \r\n 1st Qu.:0.0  \r\n Median :1.0  \r\n Mean   :0.6  \r\n 3rd Qu.:1.0  \r\n Max.   :1.0  \r\n              \r\n\r\ndf_hosp<-na.omit(df_hosp)\r\n\r\n#Task 2 - Generate Basic Visualizations\r\n\r\n# A. Side-by-Side Boxplots\r\nboxplot(BloodPressure~FirstAssess,data = df_hosp,names = c(\"Good\",\"Bad\"),ylab = \"Blood Pressure\",main = \"BP by First MD Assessment\")\r\n\r\n\r\nboxplot(BloodPressure~SecondAssess,data = df_hosp,names = c(\"Low\",\"High\"),ylab = \"Blood Pressure\",main = \"BP by Second MD Assessment\")\r\n\r\n\r\nboxplot(BloodPressure~FinalDecision,data = df_hosp,names = c(\"Low\",\"High\"),ylab = \"Blood Pressure\",main = \"BP by Final Decision\")\r\n\r\n\r\n# B. Histograms\r\n# Visualize overall distributions of Frequency and Blood Pressure\r\nhist(df_hosp$Frequency,breaks = seq(0,1,by=0.1),xlab = \"Visit Frequency\",main = \"Histogram of Visit Frequency\")\r\n\r\n\r\nhist(df_hosp$BloodPressure,breaks = 8,xlab = \"Blood Pressure\",main = \"Histogram of Blood Pressure\")\r\n\r\n\r\n#Task 3 - Interpretation and Discussion\r\n# 2-3 paragraphs addressing:\r\n# How blood pressure varies with each Doctor's assessment and the final decision:\r\n\r\n# For the first boxplot chart, the BP by first MD Assessment, the maximum looks\r\n# to be around 200 for good and 175 for bad. This is strange because a patient\r\n# with good blood pressure should not have readings higher than 150. The minimums\r\n# are around 60 for good and 30 for bad. This is also strange because I do not\r\n# know if it is possible for humans to have a blood pressure of 30. The median\r\n# seems about the same at 90-95. I also think the data may be misrepresented here\r\n# because both extreme high and low blood pressure should be in the bad category\r\n# and not the good category.\r\n\r\n# For the second boxplot chart, the BP by second MD Assessment, this chart shows\r\n# a better representation of the low blood pressure with a more reasonable range\r\n# between 60-110. However, the high blood pressure range seems to be problematic\r\n# because it also includes values that are in the low blood pressure range. Overall,\r\n# the high blood pressure range seems too large, ranging from around 20-200.\r\n\r\n# For the third boxplot, the BP by Final Decision, this seems to be the chart\r\n# that best represents the data. The low blood pressure seems reasonable with the\r\n# exception of some outliers. The grey area for the low blood pressure seems to\r\n# best represent the range of low blood pressure from 50-100, and the grey area\r\n# for the high blood pressure best represents the range of high blood pressure\r\n# from 90-175.\r\n\r\n# Any notable patterns or outliers in the histograms:\r\n\r\n# After reviewing the output from the histograms, a notable pattern that I found\r\n# in the data was in the histogram of blood pressure that shows the pattern\r\n# between the domain of blood pressure and the range of frequency. The pattern I\r\n# noticed is that patients who had a low blood pressure of 50 and a high blood\r\n# pressure of 110 had a higher frequency. The extreme outliers with a high blood\r\n# pressure of 175 and over 200 were displayed as well.\r\n\r\n# Potential clinical implications or limitations of this made up data:\r\n\r\n# A potential clinical implication/limitation of this made up data is that the\r\n# extreme blood pressure measurements in the histogram of blood pressure may not\r\n# be entirely accurate. Extreme high blood pressures can be caused by certain\r\n# reactions or behaviors, however, the blood pressure outliers may seem too high\r\n# for a patient who has good blood pressure.\r\n\r\n# How handling of NA values affected your analysis:\r\n\r\n# Handling NA values affected my analysis. NA values would reduce or alter the\r\n# analysis because it would exclude patient data. If an NA is removed, it would\r\n# turn into zero. It is strange to remove NA's this way because zero can mean\r\n# both high or low. Having a value of zero for a patient would cause a patient\r\n# to be placed in a good blood pressure when really they do not, or be placed\r\n# in a bad blood pressure when really they have a good reading. This is probably\r\n# what caused the data to become made up.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2025-09-15-module-4-assignment/module-4-assignment_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2025-09-15T19:26:11-04:00",
    "input_file": "module-4-assignment.knit.md"
  },
  {
    "path": "posts/2025-09-05-module-3-assignment/",
    "title": "Module 3 Assignment",
    "description": "Introduction to Data Frame",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-09-05",
    "categories": [],
    "contents": "\r\nTask 1. Define and Inspect Your Data\r\nIn R, create vectors (correcting any syntax issues):\r\n\r\n\r\nName <- c(\"Jeb\",\"Donald\",\"Ted\",\"Marco\",\"Carly\",\"Hillary\",\"Bernie\")\r\nABC_poll <- c(4,62,51,21,2,14,15)\r\nCBS_poll <- c(12,75,43,19,1,21,19)\r\n\r\n# Combine into a data frame\r\ndf_polls <- data.frame(Name, ABC_poll, CBS_poll)\r\n\r\n# Use str() and head() to inspect your data frame.\r\nstr(df_polls)\r\n\r\n'data.frame':   7 obs. of  3 variables:\r\n $ Name    : chr  \"Jeb\" \"Donald\" \"Ted\" \"Marco\" ...\r\n $ ABC_poll: num  4 62 51 21 2 14 15\r\n $ CBS_poll: num  12 75 43 19 1 21 19\r\n\r\nhead(df_polls)\r\n\r\n     Name ABC_poll CBS_poll\r\n1     Jeb        4       12\r\n2  Donald       62       75\r\n3     Ted       51       43\r\n4   Marco       21       19\r\n5   Carly        2        1\r\n6 Hillary       14       21\r\n\r\nTask 2. Compute Summary Statistics\r\n\r\n\r\n# Compute the mean, median, and range for each poll:\r\n\r\n# Here is the mean, median, and range for the ABC polls\r\nmean(df_polls$ABC_poll)\r\n\r\n[1] 24.14286\r\n\r\nmedian(df_polls$ABC_poll)\r\n\r\n[1] 15\r\n\r\nrange(df_polls$ABC_poll)\r\n\r\n[1]  2 62\r\n\r\n# Here is the mean, median, and range for the CBS polls\r\nmean(df_polls$CBS_poll)\r\n\r\n[1] 27.14286\r\n\r\nmedian(df_polls$CBS_poll)\r\n\r\n[1] 19\r\n\r\nrange(df_polls$CBS_poll)\r\n\r\n[1]  1 75\r\n\r\n# Add a column for the difference between CBS and ABC:\r\ndf_polls$Diff<-df_polls$CBS_poll-df_polls$ABC_poll\r\n\r\n# Here is a bar chart that shows the difference or discrepancies\r\nlibrary(ggplot2)\r\n\r\nggplot(df_polls,aes(x=Name,y=Diff,color=Diff,fill=Diff))+\r\n  geom_bar(stat=\"identity\")+\r\n  ggtitle(\"Difference between CBS poll and ABC poll\")\r\n\r\n\r\n\r\nTask 3. Discuss and Reflect\r\nOn your blog, write 2-3 paragraphs addressing:\r\nKey patterns you observe (e.g., which candidate shows the largest discrepancies).\r\nI was able to observe multiple key patterns. Both ABC and CBS polls show that Donald had the highest values in the polls, whereas Carly had the lowest values in the polls. The mean of ABC polls, 24.14286, and the mean of the CBS polls, 27.14286, indicates that both mean values are close to each other and are somewhat similar. The median of ABC polls, 15, and the median of the CBS polls, 19, indicates that both median values are close to each other and are somewhat similar, but a difference of 4 could be significant. The range of ABC polls, from 2-62, and the range of the CBS polls, from 1-75, are somewhat similar. Donald had the largest discrepancies with a difference of 13 between the ABC_poll and the CBS_poll.\r\nImpact of using made‑up data—what limitations does this introduce\r\nThe impact of using made-up data is significant. When making up numbers, the data can influence believers that it can be true. There could be a Fox News poll online that shows Donald getting the highest value. There are some limitations to this though. The data constantly changes in a poll before the final result, and the numbers may not accurately represent the polls if the data was not retrieved at a later time after it has been fully gathered.\r\nHow you might collect or validate real poll data in a true analysis.\r\nI might collect or validate real poll data in a true analysis by showing data from side-by-side instead of only showing differences. Showing data from side-by-side gives a better graphical representation of the actual numbers that are viewed and provides an easier comparison. It also helps to have a large sample size and to verify that the data from any particular source is accurate.\r\nInclude your R code (in a code chunk) and the generated plot.\r\n\r\n\r\nlibrary(tidyverse)\r\nlongData<-df_polls|>\r\n  select(Name,\r\n         ABC_poll,\r\n         CBS_poll) |>\r\npivot_longer(cols=c(\"ABC_poll\",\"CBS_poll\"),names_to = \"Poll\")\r\n\r\ndf_polls$Name<-as.factor(df_polls$Name)\r\n\r\nggplot(longData, aes(x=Name,y=value,colour=Poll,fill=Poll))+\r\n  geom_bar(stat = \"identity\",position = \"dodge\")+\r\n  geom_text(aes(label=value),vjust=-0.5,hjust=0.5)+\r\n  ggtitle(\"ABC vs. CBS Poll Data by Candidate\")\r\n\r\n\r\n\r\nHere is a link to my blog and a screenshot of my updated github repo\r\nhttps://lis4370-r-programming-journal.netlify.app/\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-09-05-module-3-assignment/poll.jpg?raw=true",
    "last_modified": "2025-09-15T15:40:07-04:00",
    "input_file": "module-3-assignment.knit.md"
  },
  {
    "path": "posts/2025-08-30-module-2-assignment/",
    "title": "Module 2 Assignment",
    "description": "Introduction to Basic R Functions and Data Structures",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-08-30",
    "categories": [],
    "contents": "\r\nTask 1. Download Import Instructions\r\nI have successfully downloaded the document and read the instructions in the cheat sheet carefully. The methods in the “readr” and “tidyr” packages to read and write data files, save data, handle missing values, expand tables, and split cells all seem very familiar to me.\r\nTask 2. Read Assigned Chapters\r\nI have successfully read the assigned chapters on R Programming and GitHub\r\nTask 3. Evaluate myMean function\r\n\r\n\r\n# Use the vector:\r\n\r\nassignment2 <- c(16, 18, 14, 22, 27, 17, 19, 17, 17, 22, 20, 22)\r\n\r\n# Consider this function:\r\nmyMean <- function(assignment2) {\r\n  return(sum(assignment) / length(someData))\r\n}\r\n\r\n# In RStudio, run myMean(assignment2) and record the output or error.\r\nmyMean(assignment2)\r\n\r\nError in myMean(assignment2): object 'assignment' not found\r\n\r\n# The error message is displayed above.\r\n\r\n\r\nThe function fails because the variable “assignment” does not exist since it has not been created yet. Also, the variable “someData” does not exist. In order to use these two variables, they have to be declared before they are used as arguments for functions. The only variable that can be used in the “myMean” function would be “assignment2” because it is the input variable for the function.\r\nHere is a corrected version of “myMean” that correctly returns the mean of “assignment2”\r\n\r\n\r\n# The corrected function\r\nmyMean <- function(assignment2) {\r\n  return(sum(assignment2) / length(assignment2))\r\n}\r\n\r\n# Call the corrected function\r\nmyMean(assignment2)\r\n\r\n[1] 19.25\r\n\r\nHere is a screenshot that displays my GitHub repository updated with the blog link and corrected myMean function:\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/r-programming-assignments/blob/main/_posts/2025-08-30-module-2-assignment/error2.jpg?raw=true",
    "last_modified": "2025-08-30T16:06:46-04:00",
    "input_file": "module-2-assignment.knit.md"
  },
  {
    "path": "posts/2025-08-25-module-1-assignment-1/",
    "title": "Module 1 Assignment 1",
    "description": "First Post.",
    "author": [
      {
        "name": "Skylar Walsh",
        "url": {}
      }
    ],
    "date": "2025-08-25",
    "categories": [],
    "contents": "\r\nThis is my first post for LIS4370\r\nTask #1\r\nCreate a GitHub Repository with a README.md file:\r\n\r\nTask #2 Set Up a Blog\r\nhttps://lis4370-r-programming-journal.netlify.app/\r\nTask #3 Install R and RStudio\r\n\r\nThe installation process of RStudio required me to install R first because\r\nRStudio relies on the R programming language for its functionality. The process\r\nbegan with going to the R project website to download the file for my operating\r\nsystem, and then run the installer. Once it was installed, I was able to go to\r\nthe website that allowed me to download the desktop installer for RStudio.\r\nThe main issue I encountered during installation was that it was difficult to\r\nhave the right Windows installer to be able to download it successfully. This\r\nproblem is what caused me to install RStudio repetitively. The way I resolved\r\nthis problem is that I got the right runtime application that supports the\r\ninstallation requirements for RStudio.\r\nIn terms of my system details, I ran a Windows 11 operating system on my PC, the\r\nR version that I currently have is R 4.4.2, and RStudio version is 2024.12.0.467.\r\nTask #4 Read Foundational Chapters\r\nAn R vector is an object or entity that acts as a container to store data. The\r\nvector is the simplest way to store more than one data value in R programs.\r\nVectors are important for data analysis because they can hold different data\r\ntypes or modes in one container. After storing data types in the container, R\r\nprograms and applications can iterate over the elements in the vector and\r\nperform many different types of operations on the different modes or types of\r\ndata contained in the vector for further analysis and extracting meaning out of\r\nlarge data sets. Elements in vectors can be modified and updated, which makes\r\nthem flexible and versatile, so if data changes, a vector is a good way to keep\r\ntrack of variables.\r\n\r\n\r\n\r\n",
    "preview": "https://github.com/skywalshUSF/R-Programming-Journal-Skylar-Walsh/blob/main/_posts/2025-08-25-module-1-assignment-1/githubrepo.png?raw=true",
    "last_modified": "2025-08-29T13:51:25-04:00",
    "input_file": "module-1-assignment-1.knit.md"
  }
]
